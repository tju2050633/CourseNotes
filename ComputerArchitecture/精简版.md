# 第一章 计算机系统结构概念

### 1.1 引言

- 计算机的发展
  - 计算机制造技术的发展
  - **计算机系统结构**的创新

- 计算机性能增长率下降
  - 功耗问题
  - 可进一步开发的**指令级并行性**很少
  - **存储器访问速度**提高缓慢
- 计算机系统结构在计算机发展中有重要作用
  - 转折点：从单纯依靠**指令级并行**转向开发**线程级并行和数据级并行**。

### 1.2计算机系统层次结构

- L6:应用语言虚拟机
- L5:高级语言虚拟机
- L4:汇编语言虚拟机
- L3:操作系统虚拟机

- L2:机器语言虚拟机
- L1:微程序虚拟机

**虚拟机**：由软件实现的机器

**翻译**：先将L+1级程序翻译成L级，再顺序执行

- 执行过程中不访问L+1级程序
- 快，但占内存

**解释**：每翻译1条L+1级程序，就直接执行一串等效L级程序，再访问下一条L+1级

- 慢，但内存占用少

**计算机系统结构定义**

- **经典定义**：程序员看到的计算机属性，即概念性结构与功能特性
- **广义定义**：指令集结构、组成、硬件（计算机设计的3个方面）
- **传统定义**：机器语言程序设计员为使其设计的程序能在计算机上正确运行所需遵循的计算机属性
- **实质**：确定计算机系统中软硬件的界面，界面之上是软件实现的功能，之上是硬件实现的功能

**计算机组成：计算机系统结构的逻辑实现**

- 着眼于物理机器级内各事件的排序方式与控制方式、各部件的功能以及各部件之间的联系

**计算机实现：计算机组成的物理实现**

- 着眼于：器件技术（起主导作用）、微组装技术

> 一种体系结构可以有多种组成，一种组成可以有多种物理实现

**透明性**：计算机技术中，本来存在的事物或属性，从某种角度看好像不存在的概念，称为透明性。

**计算机系统结构分类**

- 冯氏分类法：用系统的**最大并行度**对计算机进行分类
- **Flynn分类法**：按照指令流和数据流的多倍性分类
  - **单指令流单数据流**(SISD)：顺序处理计算机
  - **单指令流多数据流**(SIMD)：阵列处理计算机
  - **多指令流单数据**(MISD)：只存在于概念中
  - **多指令流多数据流**(MIMD)：多处理机

### 1.3 定量分析技术

**计算机系统设计定量原理**

- **以经常性事件为重点**

  - 最重要、最广泛采用的设计原则

  - 对经常发生的情况采用优化方法的原则进行选择，得到更多总体上的改进（分配更多资源等）

- **Amdahl定律**

  - 用于具体计算对当前计算机某部件改进后，能获得多少总体性能提升
  - 加快某部件执行速度能获得的系统性能加速比，受限于该部件的执行时间占比
  - **字母公式**：$K=\frac{T_前}{T_后}=\frac{1}{(1-\alpha)+\frac{\alpha}{k}}$
  - **Amdahl定律**：性能改进的递减规则
    - 如果仅仅对计算任务中的一部分做性能改进，则改进得越多，所得到的总体性能的提升就越有限
  - **推论**：部分加速比趋近于无穷，整体加速比趋近于$\frac{1}{1-\alpha}$

- **CPU性能公式**

  - $CPU时间=IC\times CPI\times 时钟周期$
  - **IC**：指令条数，取决于指令集架构和编译技术
  - **CPI**：平均每条指令所需时钟周期数，取决于计算机组成和指令集架构
  - **时钟周期**取决于硬件实现技术和计算机组成

- **程序局部性原理**

  - 程序执行时间所访问的存储器地址分布不是随机的，而是相对簇聚的。可根据**程序最近访问情况**来比较准确地预测**将要访问的指令和数据**。

  - **时间局部性**：程序即将用到的信息很可能就是目前正在使用的信息。（程序执行的90%时间执行10%的代码）

  - **空间局部性**：程序即将用到的信息很可能与目前正在使用的信息在空间上相邻或者临近

**计算机系统性能评测**

- 执行时间和吞吐率
  - **执行时间**：单个程序执行时间（PC机）
  - **吞吐率**：单位时间内完成的任务数（多任务大型机）

### 1.4 对冯氏结构改进

**对输入输出方式的改进**

- 冯氏结构以运算器为核心，所有操作控制器控制，输入输出与运算串行，运算成为瓶颈

- 程序控制
  - 程序等待：CPU反复询问是否结束
  - 程序中断：CPU可在等待期间执行其他任务，直到被中断
- DMA：外设与存储器之间建立数据通路DMA
  - 完成指定的一批数据传输之后才向CPU发结束信号
- I/O处理机：增设I/O处理机，通道、外围处理机
  - 把所有控制输入输出和传递信息的功能都从CPU处接管过来

**采用并行处理技术**

- 挖掘传统机器中的并行性
- 微操作级，指令级，线程级，进程级，任务级。。。

**存储器组织结构发展**

- 相联存储器与相联处理机
- 通用寄存器组
- CPU和主存之间加高速缓冲存储器**Cache**

**指令集发展**

- 精简指令集RISC
- 复杂指令集CISC

### 1.5 可移植性及其实现方法

**软件可移植性**：软件不经修改或少量修改，就可以由一台计算机移植到另一台计算机上运行，差别只有执行时间。

- **系列机**：同一厂家生产的具有**相同系统结构**，但具有**不同组成和实现**的**一系列不同型号计算机**。
  - **向上（下）兼容：**按某档机器编制的程序，不加修改就能运行于比它高（低）档的机器。
  - **向前（后）兼容：**按某个时期投入市场的某种型号机器编制的程序，不加修改地就能运行于在它之前（后）投入市场的机器。
  - **根本特征**：**向后兼容**
  - **关键**：对软硬件分工要充分考虑。
- **模拟和仿真**
  - **模拟**：用软件的方法在一台现有的计算机（宿主机）上实现另一种计算机（虚拟机）的指令。速度慢，性能较差。
  - **仿真**：用一台现有计算机（宿主机）上的微程序去解释实现另一台计算机（目标机）的指令。只能在系统结构差距不大的计算机间使用，速度较快。
  - 指令使用频度高则仿真，低则模拟。
- **统一高级语言**
  - 理想方法，统一的高级语言解决所有计算机之间的移植性问题
  - 如JAVA的虚拟机技术，本质是高级语言+模拟技术

### 1.6 计算机系统结构中并行性发展

**并行性**：计算机同一时刻或时间间隔内进行多种运算或操作。

##### 并行等级

- 从处理数据角度
  - 字串位串：最基本的串行处理方式，不存在并行性
  - 字串位并：同时处理一个字的全部位，开始出现并行性
  - 字并位串：同时处理许多字的同一位，有较高并行性
  - 字并位并：同时处理许多字的全部位或部分位，最高级并行性
- 从执行程序角度
  - 指令内部并行：单条指令中各微操作之间并行
  - 指令级并行
  - 线程级并行：通常是一个进程内派生的多个线程为调度单位
  - 任务或过程级并行：以子程序或进行为调度单位
  - 作业或程序级并行

##### 提高并行性措施

- 时间重叠
  - 多个处理过程在时间上相互错开，轮流使用同一套硬件各部分
  - **流水线技术**
- 资源重复
  - 大量设置重复部件
  - 单处理机中重复设置多个运算部件或处理部件；多处理机系统
- 资源共享
  - 一种软件方法，使得多个任务按一定时间顺序轮流使用同一套硬件设备，提高计算机设备利用率
  - OS的多道程序、分时系统

##### 单处理机中并行性发展

- 主导：**时间重叠**
  - 基础：**部件功能专门化**
- 资源重复
  - 多操作部件处理机，通用部件被分解为多个专用部件（可重复设置）
  - 只要指令所需部件空闲，就可以开始执行该指令
  - 实现了指令级并行
  - 如阵列处理机多个相同的处理单元在同一个控制器指挥下，按照同一条指令要求对向量或数组各元素同时进行同一操作。（SIMD）
- 资源共享
  - 用单处理机模拟多处理机功能，形成**虚拟机**
  - 如分时系统

##### 多处理机中并行性发展

- 多机系统
  - 时间重叠：同构型多处理机
  - 资源重复：异构型多处理机
  - 资源共享：分布式系统
- **耦合度**：多机系统中各计算机之间物理连接紧密程度和交互作用能力强弱
  - 紧密（直接）耦合系统
    - 物理连接频带较高
    - 通过总线或高速开关互连
  - 松散（间接）耦合系统
    - 通道或通信线路实现计算机互连
    - 可共享外设、磁盘
- 多处理机时间重叠原理
  - 处理功能分散给各专用处理机完成：功能专用化
  - 各处理机之间按时间重叠原理工作

# 第二章 计算机指令集结构

### 2.1 指令集结构分类

**区别的主要因素：CPU中存储操作数的存储单元类型**

【指令集结构】

**操作数给出方式**：

显式给出：用**指令字中的操作数字段**给出

隐式给出：使用**事先约定好的存储单元** 

- **堆栈结构**
  - 操作数隐式
- **累加器结构**
  - 半隐半显
- **通用寄存器结构**（如今大多数计算机采用）
  - 全显式
  - 按操作数来源不同进一步划分
    - 寄存器-存储器结构（RM结构）
    - 寄存器-寄存器结构（RR结构），load-store结构，只有load和store指令能访问存储器

【堆栈结构和累加器结构特点】

- 指令字比较短，程序占用空间小
- 堆栈型计算机不能随机访问堆栈，只能访问栈顶
- 累加型计算机中只有一个中间结果暂存器（即累加器），要频繁访问存储器

【通用寄存器结构特点】

- 灵活性和提高性能方面有明显优势

- 寄存器访问速度比存储器快
- 对编译器，更容易有效分配和使用寄存器，便于实现流水线技术
- 寄存器可以存放变量，减少对存储器的访问，加快程序执行速度
- 使用更少的地址位（相对于存储器）来寻址，减短了目标代码

### 2.2 寻址方式

**定义：一种指令集结构如何确定要访问的数据地址（实际地址、有效地址）。**

多种寻址方式可以显著减少程序指令条数，还可能增加计算机实现复杂度和指令CPI（CISC具有多种寻址方式）。

使用频度最高（MIPS采用）：

- 立即数寻址：Add R4 , #3，Regs[R4]←Regs[R4]＋3
- 偏移量寻址：Add R4 , 100(R1)，Regs[R4]←Regs[R4]＋Mem[100+Regs[R1]]
  - 以0为偏移量：寄存器间接寻址
  - 以R0（内容永远为0）为基址寄存器：绝对寻址

### 2.3 指令集结构功能设计

首先考虑实现哪些基本功能，设计实际上是确定软硬件功能分配。（频度高的用硬件）

- **完整性**
  - 指令足够、功能齐全、使用方便
  - 通用计算机系统基本指令：算术和逻辑运算+数据运输+控制+系统
- **规整性**
  - 对称性：所有与指令集有关的存储单元的使用、操作码的设置等都是对称的
  - 均匀性：指对于各种不同的操作数类型、字长、操作种类和数据存储单元，指令的设置都要同等对待
  - 很难做到完全规整，实现都是有限的
- **高效率**
  - 指令执行速度快，使用频度高
- **兼容性**

---

【指令集发展方向——CISC（Complex Instruction Set Computer）】

> 向用户提供了数量很多、功能多样的指令

- **面向目标程序**增强指令功能（提高计算机系统性能最直接办法）
  - 思想
    - 使用频度高的指令，用硬件加快执行（减少程序执行时间）
    - 使用频度高的指令串，用一条新指令代替（缩短程序长度）
  - 改进方面
    - 增强运算型指令功能
    - 增强数据传送指令功能
    - 增强程序控制指令功能
- **面向高级语言**的优化实现改进指令集
  - 思想：大多数高级语言与一般的机器语言差距很大，这就为高级语言程序编译带来问题，因此改进指令集，增强对高级语言和编译器的支持，缩小高级语言与机器语言的差距，从而提高性能。
  - 增强对高级语言和编译器的支持
  - 高级语言计算机（激进）
- **面向操作系统**的优化实现改进指令集
  - 改进的指令集为下面所示，使用频率低但不可缺少
    - 处理机工作状态和访问方式的切换
    - 进程的管理和切换
    - 存储管理和信息保护
    - 进程的同步和互斥，信号灯管理

**缺陷（产生RISC的原因）**

- 各种指令使用频度相差悬殊，许多指令很少用到
- 指令集庞大，指令条数多，许多指令功能复杂
- 许多指令操作复杂，CPI大，执行速度慢
- 指令功能复杂、规整性不好，不利于采用流水技术提高性能

---

【指令集发展方向——RISC（Reduced Instruction Set Computer）】

> 尽可能精简指令集

**原则**：

- 指令条数少而简单
- 采用简单、统一的指令格式，减少寻址方式
- 指令的执行在单个机器周期内完成
- 只有load、store可以访问存储器
- 大多数指令采用硬连逻辑实现
- 强调优化编译器的作用，为高级语言程序生成优化代码
- 充分利用流水线技术提高性能

**控制指令**：用来改变控制流

- 无条件改变：跳转
- 有条件改变：分支（大部分）

### 2.4 操作数类型和大小

**数据表示**

计算机硬件能够直接识别，指令集可以直接调用的数据类型。

**数据结构**

由软件进行处理和实现的各种数据类型。

**表示操作数类型方法**

- 由指令中的操作码指定操作数类型
- 给数据加tag（动态开销太大，很少用）

### 2.5 指令格式设计

确定指令字的编码方式，影响代码长度、处理器处理速度。

**指令**：地址码+操作码（一般采用固定长度操作码，便于硬件处理）

**寻址方式表示**

- 与操作码一起编码，适用于load-store结构，寻址方式少的情况
- 设置专门地址描述符，适用于多个操作数、多种寻址方式的情况

> 权衡指令字长、寄存器数目和寻址方式的数目。

- 可变长度编码：适用于寻址方式和操作种类很多的情况，但会使指令间的指令字长和执行时间相差太大
  - 操作码-地址描述符1-地址码1-...-地址描述符n-地址码n
- 固定长度编码：适用于寻址方式和操作种类少的情况，降低译码难度
  - 操作码-地址码1-地址码2-地址码3
- 混合型编码

### 2.6 MIPS指令集结构——一种典型的RISC结构

**寄存器**

- 32个64位通用寄存器
  - R0～R31
  - R0永远为0
- 32个64位浮点数寄存器（单、双）
  - F0～F31
  - 可以存32个单精度浮点数（只用到了一半），也可以存32个双精度浮点数
- 浮点状态寄存器，保持有关浮点操作结果的信息

**数据表示**

- 整数：字节8、半字16、字32、双字64
- 浮点数：单32、双64
- MISP的操作针对**双字整数、单精度浮点数和双精度浮点数**
- 字节、半字或者字在装入64位寄存器时，用**零扩展或者用符号位扩展**来填充该寄存器的剩余部分。装入以后，对它们将按照64位整数的方式进行运算

**指令格式**

- 寻址方式编码到操作码中；所有指令32位；操作码6位

- I类指令
  - 包括所有load和store指令、立即数指令、分支指令、寄存器跳转指令、寄存器链接跳转指令
  - 立即数字段16位，提供立即数或偏移量
  - 0\~5操作码，6\~10rs，11\~15rt，16\~31立即数
- R类指令
  - ALU指令、专用寄存器读写指令、move指令
  - 0\~5操作码，6\~10rs，11\~15rt，16\~20rd，21\~25sham，26\~31func
- J类指令
  - 跳转指令等
  - 0\~5操作码，6\~31与PC相加的偏移量

**寻址方式**

- 立即数（16位）寻址
- 偏移量（16位）寻址
  - 以0为偏移量：寄存器间接寻址
  - 以R0为基址寄存器：16位绝对寻址
- 按字节寻址，地址64位
- 存储器访问边界对齐

**操作**

load&store、ALU、分支与跳转、浮点操作

「解释指令间的符号」

- $x\leftarrow _ny$从y传送n位到x
- 下标：字段中具体的位
- Mem：主存，按字节寻址
- 上标：对字段的复制次数
- ##：两个字段的拼接

$Regs[R8]_{32..63}\leftarrow (Mem[Regs[R6]]_0)^{24} \#\# Mem[Regs[R6]]$

# 第三章 流水线技术

### 3.1 基本概念

**流水线**：把一个重复的过程分解为若干子过程，每个子过程由专门的功能部件实现，这样每个子过程就可以和其他子过程并行进行。

**流水线深度**：流水线的段数，也即同时可以存在于流水线中子任务最大数量

**流水线应用**

- 指令解释执行——指令流水线
- 运算执行过程——运算操作流水线（部件级流水线）

**流水线分类**

- 按**功能**分类
  - 单功能流水线：一种固定功能
  - 多功能流水线：多种功能，即流水线各段可以进行不同的连接
- 按**同一时间各段连接方式**分类（只对多功能流水线分）
  - 静态流水线：同一时间内各段只能按同一种功能的连接方式
  - 动态流水线：同一时间内多功能流水线各段可以以不同方式连接
  - **时空图上体现为两种运算能不能“嵌入”到前面运算结果一出来就进行另一种运算，即动态流水线不需要等前一种运算排空就可以开始，效率高一些**
- 按**流水的级别**分类
  - 部件级流水线：**运算操作流水线**，算术逻辑运算部件分段
  - 处理机级流水线：**指令流水线**，指令的解释执行过程
  - 处理机间流水线：**宏流水线**，两个以上处理机串行连接，对同一数据流进行处理，每个处理机完成任务中的一部分（异构型多处理机）
- 按**是否有反馈回路**分类
  - 线性流水线：没有反馈回路，每段最多流经一次
  - 非线性流水线：有反馈回路，可多次走同一段（可能发生争用流水线，需要调度）
- 按**任务的流入和流出顺序**分类
  - 顺序流水线：流入流出顺序一致
  - 乱序流水线：流入流出顺序不同

### 3.2 流水线性能指标

**1. 吞吐率$TP$**：单位时间内流水线所完成任务数量

$TP=\frac{n}{T_K}$

时空图上计算方法为：**数一共几个任务 / 最后一个任务完成时的时间**

**2. 加速比$S$**：完成同一批任务，不使用流水线所用时间与使用流水线时间之比。

$S=\frac{T_S}{T_K}$

时空图上计算方法为：**执行任务阴影面积 / 最后一个任务完成时的时间**

**3. 效率$E$**：流水线中设备实际使用时间与整个运行时间之比，即设备利用率

$E=\frac{Kn\Delta t}{KT_K}=TP\Delta t=\frac{S}{K}$

时空图上计算方法为：**执行任务所占据时空矩形面积 / 运行时间内时空矩形面积**

**流水线设计中的若干问题**

- **瓶颈问题**
  - 细分瓶颈段（将对应部件拆成多份、串联）
  - 重复设置瓶颈段（重复对应部件多次、并联）
- **流水线的额外开销**
  - 流水线寄存器延迟
    - 建立时间：触发写操作前时钟信号到达之前寄存器必须保存稳定的时间
    - 传输延迟：时钟信号到达后寄存器输出可用时间
  - 时钟偏移开销：时钟到达各流水寄存器的最大差值
- **冲突问题**
  - 指令之间存在关联，则它们之间需要相互等待，引起流水线停顿

### 3.3 流水线相关与冲突

**经典5段RISC流水线**

- **取指令**周期IF
- **指令译码/读寄存器**周期ID
- **执行/有效地址计算**周期EX
- **存储器访问/分支完成**周期MEM
- **写回**周期WB

**相关**：两条指令之间存在某种依赖关系，可能导致不能在流水线中重叠执行

- **数据相关**（反映了数据流动关系：从生产者流动到消费者）**RAW**
  - 指令j使用指令i产生的结果
  - 指令j与指令k数据相关、而指令k与指令i数据相关（**传递性**）
- **名相关**（使用相同的名但是没有数据流动，可以用**换名技术**消除名相关）
  - **反相关**：指令j写的名与指令i读的名相同**WAR**
  - **输出相关**：指令j和指令i写相同的名**WAW**
- **控制相关**（由分支指令引起的相关，需根据分支指令的执行结果来确定后读指令是否执行）
  - 与分支指令**控制相关**的指令不能移到分支之**前**
  - 与分支指令**不控制相关**的指令不能移到分支之**后**

**冲突**：由于相关的存在，使得指令流中的下一条指令不能在指定时钟周期执行

- **结构冲突**：硬件资源满足不了指令重叠执行的要求

  > 功能部件不完全流水线或资源份数不够时易发生此冲突

  如处理机只有一个存储器，数据指令放一起，访存操作可能和取指令发生访存冲突（结构冲突）。解决方法：

  - 插入停顿在前一个指令访存操作之后，即**气泡**
  - 将指令和数据存在不同存储器中

- **数据冲突**：需要用到前面指令的执行结果

  >  相关的指令靠的太近时易发生此冲突

  分类：写后读冲突RAW（真数据相关），写后写冲突WAW（输出相关，只发生在多段有写功能的流水线中，经典5段流水线不会出现），读后写冲突WAR（反相关）

  - 解决方法一：写操作安排在时钟周期前三排，读操作在后半拍
  - 解决方法二：定向技术（硬件），从产生结果的地方（EX段和MEM段之间的寄存器）直接拉一条线到需要此数据的地方，即可在数指令存入存储器之前将其送给需要之处
  - 解决方法三：流水线互锁机制，检测发现数据冲突，并使流水线停顿，直至冲突消失

  - 解决方法四：依靠编译器进行指令调度（理论上可以解决任何冲突）

- **控制冲突**：遇到分支指令和其他会改变PC值的指令引起的冲突

  控制冲突可能比数据冲突损失更多性能。

  分支指令

  - 分支成功——改变PC值转至目标地址
  - 分支失败：继续后继地址


**冻结或排空流水线**

- 一旦在ID段检测到分支指令，就停止后面所有指令，直到分支到达MEM段，确定是否成功并计算PC值
- 最简单，但延迟3个时钟周期，性能损失最大

减少分支延迟

- 尽早判断出分支转移是否成功
- 尽早计算出分支目标地址

> 基于这两项，使用软件方法在ID段完成分支指令处理

**预测分支失败**

遇到分支指令，沿着分支失败继续处理指令，确定分支失败了就继续执行，否则将分支指令之后取出的指令转化为空操作（idle），按分支成功目标地址重新取指令执行。

必须保证分支结果出来前不会改变处理机状态，以便预测出错时可以回退原状态。

**预测分支成功**

和预测分支失败类似，只是按分支成功处理。

对于经典5段流水线，计算目标地址和判断是否分支成功在同一流水段，所以此方法没什么用。

**延迟分支**

在分支指令后面加上几条指令（无论分支是否成功都必须执行的指令，由编译器决定），将其看成一个整体（**延迟槽**）

编译器决定调度方法

- 从前调度
- 从目标处调度
- 从失败处调度

限制

- 被放入延迟槽的指令需要满足一定条件
- 编译器具有预测分支转移方向的能力

> 分支取消机制：分支指令隐含了预测的分支执行方向，当分支的实际执行方向和预测的一样时，执行分支延迟槽中指令，否则将其中的指令转化为一个空操作。

### 3.4 流水线实现

**MIPS指令子集的一种简单数据通路**

<img src="img/实现MIPS指令的数据通路.png">

- 取指令周期IF
  - 根据PC中的地址取出指令，放入指令寄存器IR
  - PC+4指向下一条指令，其地址放入临时寄存器NPC
- 指令译码/读寄存器周期ID
  - 对指令译码，并以rs、rt字段为地址访问通用寄存器组，将读出的操作数放入临时寄存器A、B（两个都读，但不一定用得到）
    - 指令译码和访问通用寄存器组并行
  - 同时IR的低16位符号位扩展，存入Imm（可能用不到）
- 执行/有效地址计算周期EX
  - 存储器访问指令：ALU将操作数相加形成有效地址，存入临时寄存器ALU0
    - $ALU_0\leftarrow A+Imm$
  - 寄存器-寄存器ALU指令：ALU根据func字段指出的操作类型对啊、B中数据进行操作，结果存入ALU0
    - $ALU_0\leftarrow A func B$
  - R- I ALU指令：ALU根据操作码op指出的操作类型对A和Imm中的数据进行运算，存入ALU0
    - $ALU_0\leftarrow A\ op\ Imm$
  - 分支指令：计算目标地址（$NPC+Imm左移两位$），存入ALU0；判断上一周期读入的A的值，决定分支是否成功
    - $ALU_0\leftarrow NPC+(Imm<<2)$
    - $cond\leftarrow (A==0)$
- 存储器访问/分支完成周期MEM
  - 统一操作：更新PC，除分支操作，其余均有$PC\leftarrow NPC$
  - 个性操作：
    - 存储器访问指令：$LMD\rightarrow MEM[ALU_0]或MEM[ALU_0]\leftarrow B$
    - 分支指令：若cond为真，将ALU0目标地址放入PC。$if(cond)\ PC\leftarrow\ ALU_0\ else\ PC\leftarrow NPC$
- 写回周期WB
  - R-R ALU指令：$Regs[rd]\leftarrow ALU_0$
  - R-I ALU指令：$Regs[rt]\leftarrow ALU_0$
  - load指令：$Regs[rt]\leftarrow LMD$

**基本MIPS流水线**

在上述数据通路上加上流水寄存器（各段之间）；增加向后传递IR和从MEM/WB.IR回送到通用寄存器组的连接；将PC的修改移到IF段，为取下一条指令做准备，得到下面的M IPS流水线数据通路。

> 流水寄存器作用
>
> - 将各段工作分隔开，使之不会互相干扰
> - 保存各段处理结果
> - 向后传递数据或控制信息

<img src="img/基本MIPS流水线-1.png">

# 第四章 指令级并行

### 4.1 指令级并行概念

**流水线处理机实际CPI**

$CPI_{流水线}=CPI_{理想}+停顿_{结构冲突}+停顿_{数据冲突}+停顿_{控制冲突}$

**指令动态调度**

在指令执行过程中依靠专门硬件对代码进行调度，可以在保持数据流和异常行为的情况下通过硬件对指令执行顺序进行重新安排，减少相关导致的停顿。

优点：

- 能处理一些编译时情况不明的相关（如涉及存储器访问的相关），并简化了编译
- 能使本来面向某一流水线优化编译的代码在其他流水线（动态调度）上也能高效执行

缺点：硬件复杂度显著增加

**动态调度基本思想**

将ID段细分为

- 流出：没有结构冲突就流出
- 读操作数：等待数据冲突消失，然后读操作数

乱序执行大大增加了异常处理复杂度，为保证正确的异常行为，动态调度的处理机只有确切知道该指令被执行后才允许它产生异常。

**Tomasulo算法**

<img src="img/Tomasulo算法.png">

- 流出
  - 前提：该指令操作所要求的**保留站有空闲**，若没有则产生**结构冲突**、不能流出
  - 操作数已准备好：直接放入保留站，与存该数的寄存器再无关
  - 操作数未准备好：将产生操作数的**保留站号放入保留站**（即寄存器换名，消除了WAR冲突），监视CDB，一旦产生该操作数立刻取用
- 执行
  - 前提：**操作数都准备好**（靠推迟执行的方法解决RAW冲突）
  - 保留站可能出现同一周期内多个指令的操作数同时准备好
    - 同一功能部件一次只能执行一条
    - 不同功能部件可以并行执行
  - load和store指令执行步骤
    - 计算有效地址
    - 把有效地址放入load/store缓冲器
  - 需要按顺序进行有效地址计算来保证顺序
- 写结果
  - 功能部件完成计算后**结果放在CDB**上，所有需要此结果的Reg和保留站可以同时收到该数据
  - 标志：上图标识字段由4位二进制数字构成，表示5个保留站、6个load缓冲器，特殊编号0表示操作数已就绪

每个保留站有下面8个字段

- Op：操作
- Qj Qk：将产生操作数的保留站号，若**为0**表示保留站或缓冲器单元中的Vj Vk字段中的**数据就绪**
- Vj Vk：源操作数值
- Busy：yes表示本保留站或缓冲单元忙
- A：仅load和store缓冲器有该字段，开始存Imm后存有效地址
- Qi：寄存器状态表，每个寄存器在该表中有对应的一项，用于把结果写入该寄存器对应的保留站中，为0表示当前没有正在执行的指令要写入该寄存器，也即寄存器内容就绪

### 4.2 动态分支预测技术

在程序运行时根据分支指令过去的表现预测其未来行为。

关键

- 记录分支历史信息
- 如何根据历史信息预测分支去向，以及预测错误时如何恢复现场

**分支历史表BHT**

> 只有连续两次预测错误才改变预测方向

<img src="img/分支历史表.png">

优点：最简单，通常采用2位二进制位记录历史

缺点：只有判定分支是否成功和目标地址计算能并行执行、且前者更费时时才有用

**分支目标缓冲器BTB**

- 看作专门硬件实现的一张表格

  - 执行过的成功的分支指令地址（匹配标识）
  - 对应的预测的分支目标地址

  每次预测分支指令，就拿其地址与表格中的对比，有匹配说明该分支上一次执行时成功，这次也预测成功，分支目标地址由匹配项第二个字段给出。

  若预测成功则继续执行后面的指令、没有延迟，预测失败则更新BTB。

- 另一种实现形式：在BTB中存一条或多条分支目标处指令

  - 好处：更快获得目标指令；可以一次获得多条指令，对多流出处理机有必要

**基于硬件的前瞻执行**

- 对Tomasulo算法的扩充
  - 允许乱序执行，但要求顺序确认
  - 在被确认之前不难进行不可恢复操作
- 要将写结果分成两段
  - 写结果：将结果写入ROB，通过CDB在指令间传送结果，在指令执行完全被确认前暂存数据
  - 指令确认：分支指令结果出来后再看是否要将ROB中存的东西写入Reg或Mem

**ROB每一项组成**

- 指令类型
- 目标地址
- 数据值字段：保存前瞻执行结果
- 就绪字段：指出指令是否已完成执行且数据已就绪

**前瞻执行与Tomasulo算法区别**

- 保留站换名功能由ROB完成，保留站只管流出到开始执行期间存操作码和操作数
- 由于每条指令在ROB中都有对应项，所以执行结果用ROB项目编号做标识，保留站中记录分配给该指令的ROB编号
- 缺点：硬件太复杂，控制方面硬件增加很多

**指令执行过程**

- 流出
  - 前提：**有空保留站**且**有空闲ROB**
  - 把ROB编号放入保留站r
- 执行
  - 前提：操作数就绪，否则一直监听CDB
- 写结果
  - 将指令相应的ROB项的编号放到CDB上，经CDB写到ROB及所有等待的保留站，然后释放该结果的保留站
- 确认

### 4.3 多指令流出技术

**多流出技术**

- 超标量处理机：每个周期流出条数不固定，上限n则为n-流出
  - 通过重复设置多份硬件提高性能
  - 指令调度：动态Tomasulo，静态编译器
- 超长指令字VLIW：流出条数固定
  - 只可通过编译器静态指令调度

**超流水线处理机**

>  一个时钟周期内可以分时流出多条指令的处理机。

只需要增加少量硬件，通过各部分硬件的充分重叠工作来提高性能。

超标量处理机采用**空间并行性**，超流水线处理机采用**时间并行性**。

### 4.5 循环展开和指令调度

限制条件

- 程序固有的指令并行性
- 流水线功能部件的执行延迟

**循环展开技术**

把循环体的代码复制多次并按顺序排放，然后相应调整循环结束条件

优点：可以将多次循环的代码合在一起调度，消除了中间的分支指令。

# 第五章 存储系统

### 5.1 存储系统基本知识

**目标**:容量大、速度快、价格低

**办法**:采用多级存储层次结构

**依据**

- 程序访问的局部性原理
  - 定义:对绝大多数程序来说，程序所访问的指令和数据在地址上不是均匀分布的，而是相对簇聚的
  - 分类:时间局部性(要用到的刚好就是现在正在用的)、空间局部性(要用的就在附近) 
- 存储系统的多级层次
  - 访问时间:越靠近CPU越短-> 从CPU的⻆度来看存储系统的速度接近于M1
  - 容量:越远离CPU越大 ->从CPU的⻆度来看存储系统的容量接近Mn
  - 平均每位价格:越远离CPU越小

**存储系统参数性能**

- 存储容量$S=S_n$（小容量级别存储器存放大容量级别存储器的数据副本）
- 平均每位价格$C=\frac{C_1S_1+C_2S_2}{S_1+S_2}$，S2远大于S1，C约等于C2
- 命中率H：CPU访问存储系统时在M1中找到信息概率：$H=\frac{N_1}{N_1+N_2}$，N1、N2分别为访问M1和M2次数
- 不命中率F=1-H
- 平均访存时间
  - $T_A=T_1+FT_M$，$T_M=T_2+T_B$为不命中开销，$T_B$为调块开销

**三级存储系统**

Cache-主存-磁盘

### 5.2 Cache基本知识

**映像规则**

- 全相联映像——任何块可以放在任何位置
- 直接映像——每个块固定唯一位置
- 组相联映像——折中

**查找方法**

Cache中有一个目录表，每个块都在其中有唯一的一项，用于指出当前块中存放的信息是哪个 主存块的 -> 实际上是主存块地址的高位部分->标识

**替换算法**

- 随机法
- 先进先出法FIFO
- 最近最少使用法LRU

**写策略**

- 写直达法：写Cache时把主存也写了
- 写回法：拷回法，写Cache的时候先不写主存，只有Cache块被替换的时候，才写回下一级存储器

**Cache性能分析**

- 平均访存时间：衡量存储系统性能的**间接指标**
  - 平均访存时间=命中时间+不命中率*不命中开销
- 程序执行时间：更好反映存储系统性能
  - CPU时间=IC（CPI理想+每条指令平均访存次数\*不命中率\*不命中开销）*时钟周期时间

### 5.3 降低Cache不命中率

- 不命中类型
  - 强制性不命中——第一次访问一个块的时候发生的不命中 -> 首次访问不命中/冷启动不命中
    - 解决办法:增加块大小，预取
  - 容量不命中——某些块为了给其他块腾地方，调出去之后又要被访问发生的不命中
    - 解决办法:增加容量
  - 冲突不命中——在组相联或直接映像Cache中，若太多的块映像到同一组中，就会出现该组中某个 块被别的块替代，然后又要被访问的情况
    - 解决办法:提高相联度

1. 增加块大小
2. 增加Cache容量
3. 提高相联度
4. 伪相联Cache
5. 硬件预取
6. 编译器控制的预取
7. 编译优化
8. 牺牲Cache

### 5.4 减少Cache不命中开销

1. 采用两级Cache
2. 让读不命中优先于写
3. 写缓冲合并
4. 请求字处理技术
5. 非阻塞Cache技术

### 5.5 减少命中时间

1. 使用容量小结构简单的Cache
2. 虚拟Cache
3. Cache访问流水化
4. 踪迹Cache

### 5.6 并行主存系统

> 一个访问周期内能并行访问多个存储字的存储器，可以有效提高存储器带宽

**带宽**：$B_M=\frac{W}{T_M}$

- **单体多字存储器**
  - 存储器每个存储周期读出m个CPU字：$B_M=m\times\frac{W}{T_M}$
  - 实际带宽小于理论值：一次读出的m个指令字不一定都用到
- **多体交叉存储器**
  - 多个单体多字存储器构成
  - 高位交叉：列优先。一个存储体内低位连续。连续字分布在同一个存储器内。
  - **低位交叉**：行优先。一个存储体内高位连续。连续字分布在不同存储器条带上。

# 第六章 输入输出系统

### 6.1 I/O系统性能

- **可靠性**
  - 系统从某个初始参考点开始一直连续提供服务的能力
  - 衡量标准——平均失效前时间(Mean Time to Failure，MTTF)
  - MTTF的倒数就是系统的失效率
  - 中断服务的时间用平均修复时间(Mean Time to Repair，MTTR)

- **可用性**
  - $可用性=\frac{MTTF}{MTTF+MTTR}$
  - 系统正常工作的时间在连续两次正常服务间隔时间中所占的比率
  - 其中MTTF+MTTR可以用平均失效间隔时间(Mean Time Between Falirue)

- **可信性**
  - 服务的质量——在多大程度上可以认为服务是可靠的
  - 不可衡量

> 假定每个部件生存期服从指数分布，各部件故障相互独立，给定每个部件的MTTF为x小时，则整个系统失效率为所有MTTF倒数之和；系统MTTF为失效率的倒数。

### 6.2 廉价磁盘冗余阵列RAID

**磁盘阵列**

- 使用多个磁盘来代替大容量磁盘存储系统
- 好处:大容量、并行可以提高性能 ◦交叉存放:以条带为单位将数据均匀分布到多个磁盘上，因而可以并行地处理多个数据读/写请求，从而提高I/O性能
  - 多个独立的请求可以由多个磁盘来并行地处理，减少了I/O请求排队等待时间
  - 一个请求如果是访问多个块，也可以由多个磁盘合作并行处理，提高了单个请求的数据传输 率
- 磁盘数量越多，性能提高越多，可靠性下降——可靠性将为单个磁盘的1/N
- 可以在磁盘阵列中加设冗余信息盘来解决此问题——当某个磁盘出问题的时候可以利用冗余盘中的信息重新构建，只有两个磁盘都坏了的时候磁盘阵列才不能工作，而修复时间很短，所以可靠性比

​		单个磁盘高很多 -> 廉价磁盘冗余

- 1阵列(**Redundant Array of Inexoensive Disks**，**RAID**)
- 不同磁盘阵列的区分特征——数据交叉存放的粒度、荣誉数据的计算方法及在磁盘阵列中的存放方式

**细粒度磁盘阵列**

- 把数据分割成较小的单位交叉存放
- 优点:几乎所有I/O请求都能获得很高的数据传输率
- 缺点:只有一个逻辑上的I/O在处理当中，每个磁盘都会为每一个请求进行定位而浪费时间

**粗粒度磁盘阵列**

- 数据以较大的单位交叉存放
- 优点:规模较小的数据访问只需要访问较少的几个磁盘，只有较大规模的访问才需要访问所有盘， 多个较小规模的请求可以同时得到处理，而较大的数据又传输效率挺高

### RAID

- RAID0：非冗余磁盘阵列（无）
- RAID1：镜像磁盘（整体copy一份）
- RAID2：存储器式冗余阵列，冗余磁盘存汉明纠错码（无应用）
- RAID3：位交叉奇偶校验磁盘阵列（每个条带的校验码形成校验条带，放在一个盘）
- RAID4：块交叉奇偶校验磁盘阵列（校验块集中在一个盘都有）
- RAID5：块交叉分布奇偶校验磁盘阵列（校验块每个盘都有）
- RAID6：P+Q双校验磁盘阵列（空间开销是RAID5的两倍）
- RAID10：先镜像后条带存放
- RAID01：先条带存放后镜像

### 6.3 通道处理机

> 专⻔负责整个计算机系统的输入输出工作的专用处理机

**通道功能**

- 接收CPU发来的I/O指令，根据指令选择制定的外设与通道相连

- 执行通道程序 -.> 从主存中逐条取出通道指令、译码、执行操作
- 给出外设中要进行读/写操作的数据的所在地址
- 给出主存缓冲区的首地址
- 控制外设与主存缓冲区之间的数据传送⻓度
- 指定传送工作结束时要进行的操作
- 检查外设的工作状态是否正常，并将该状态信息送往主存指定单元保存
- 数据传输过程中完成必要的格式转换

**4级层次结构输入输出系统**

- CPU
- 通道
- 设备控制器
- 外设

**工作过程**

- 用户程序用访管指令进入管理程序，尤其编制一个通道程序、开启通道
- 通道处理机执行通道程序，完成指定的数据输入/输出工作
- 通道结束后向CPU发送中断请求，CPU再次进入管态

**通道种类**

$n：字节数，p：设备数，k：块大小，T_S：设备连接时间，T_D：传输一个字节时间$

- 字节多路通道
  - 依次传输各设备的第1、2、。。。n个**字节**
  - 最大流量$\frac{1}{T_S+T_D}$
- 选择通道
  - 选择一个设备，完成全部传输
  - 最大流量$\frac{1}{\frac{T_S}{n}+T_D}$
- 数组多路通道
  - 依次传输各设备的第1、2、。。。n个**块（如512B）**
  - 最大流量$\frac{1}{\frac{T_S}{k}+T_D}$

### 6.4 I/O与操作系统



# 第八章 多处理机

### 8.1 对称式共享存储器系统结构





### 8.2 分布式共享存储器系统结构



### 8.3 通信机制



### 8.4 Cache一致性协议

**监听协议**



**目录协议**



**目录三种结构**





### 8.5 同时多线程（TLP线程级并行）